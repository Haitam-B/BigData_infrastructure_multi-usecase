# Master URL for the cluster
spark.master                          yarn

# Deployment mode
spark.submit.deployMode               client

# Number of cores to use for the driver process
spark.driver.cores                    1

# Amount of memory to use for the driver process
spark.driver.memory                   2g

# Number of cores to use for each executor
spark.executor.cores                  2

# Amount of memory to use per executor process
spark.executor.memory                 4g

# Number of executors to launch for this session
spark.executor.instances              2

# Address of the YARN ResourceManager
spark.yarn.resourcemanager.address    master:8032

# Address of the YARN ResourceManager's scheduler
spark.yarn.resourcemanager.scheduler.address master:8030

# Web UI address of the YARN ResourceManager
spark.yarn.resourcemanager.webapp.address http://master:8088

# Hadoop configuration directory
spark.hadoop.fs.defaultFS             hdfs://master:9000

# Enable YARN timeline service integration (optional)
spark.yarn.timeline-service.enabled   true

# Path to the directory where Spark is installed on worker nodes
spark.yarn.jars                       hdfs://master:9000/spark/jars/*

# File to use as a log4j configuration file for the Spark driver and executors
spark.driver.extraJavaOptions         -Dlog4j.configuration=file:/opt/spark/conf/log4j.properties
spark.executor.extraJavaOptions       -Dlog4j.configuration=file:/opt/spark/conf/log4j.properties

# Application classpath for Spark applications
spark.yarn.application.classpath      /opt/hadoop/etc/hadoop, /opt/hadoop/share/hadoop/common/*, /opt/hadoop/share/hadoop/common/lib/*, /opt/hadoop/share/hadoop/hdfs/*, /opt/hadoop/share/hadoop/hdfs/lib/*, /opt/hadoop/share/hadoop/mapreduce/*, /opt/hadoop/share/hadoop/mapreduce/lib/*, /opt/hadoop/share/hadoop/yarn/*, /opt/hadoop/share/hadoop/yarn/lib/*

# Enable dynamic allocation of executors
spark.dynamicAllocation.enabled       true

# Initial number of executors
spark.dynamicAllocation.initialExecutors 2

# Minimum number of executors
spark.dynamicAllocation.minExecutors  2

# Maximum number of executors
spark.dynamicAllocation.maxExecutors  10

# Executor idle timeout before they are released
spark.dynamicAllocation.executorIdleTimeout 60s

# Enable event logging
spark.eventLog.enabled                true

# Directory for event logs
spark.eventLog.dir                    hdfs://master:9000/spark-logs

# Compression codec for event logs
spark.eventLog.compress               true

# Spark history server settings
spark.history.fs.logDirectory         hdfs://master:9000/spark-logs
spark.history.fs.cleaner.enabled      true
spark.history.fs.cleaner.maxAge       7d
